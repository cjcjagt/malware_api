{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Masking, LSTM, Dense, Bidirectional\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "## 设置字体\n",
    "from matplotlib.font_manager import FontProperties\n",
    "fonts = FontProperties(fname = \"/Library/Fonts/华文细黑.ttf\",size=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\"Spyware\", \"Downloader\", \"Trojan\", \"Worms\", \"Adware\", \"Dropper\", \"Virus\", \"Backdoor\"}\n",
    "classes = {\"Spyware\": 0, \"Downloader\": 1, \"Trojan\": 2, \"Worms\": 3, \"Adware\": 4, \"Dropper\": 5, \"Virus\": 6, \"Backdoor\": 7}\n",
    "dev_sample_percentage = 0.3\n",
    "batch_size=128\n",
    "num_step = 100\n",
    "class_num = 8\n",
    "sequence_length = 10000\n",
    "embedding = 100\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            print(str(fname)+\"is doing\")\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                yield line.split()\n",
    "\n",
    "def shuffleData(datas,labels,tokenflag=True):\n",
    "    all_text_seq =[]\n",
    "    if(tokenflag):\n",
    "        sentences = MySentences('data/') # a memory-friendly iterator\n",
    "        model = gensim.models.Word2Vec(sentences,min_count=0)\n",
    "        model.save('myWord2VecModel.model')\n",
    "\n",
    "    gensim_model = gensim.models.Word2Vec.load('myWord2VecModel.model')\n",
    "    print(len(gensim_model.wv.vocab))\n",
    "    seq = []\n",
    "    for line in datas:\n",
    "        for word in line:\n",
    "            if word in gensim_model:\n",
    "                seq.append(gensim_model[word] )\n",
    "            else:\n",
    "                seq.append(np.random.random((100)))\n",
    "        array = np.asarray(seq, dtype='float32')\n",
    "        all_text_seq.append(array.mean(axis=0))\n",
    "        seq = []\n",
    "    all_text_test = pad_sequences(all_text_seq, maxlen=sequence_length,padding='post', value=0)\n",
    "\n",
    "    label_one_hot = np.zeros((len(labels), class_num), dtype=np.int)\n",
    "    for i in range(len(labels)):\n",
    "        label_one_hot[i][labels[i]] = 1\n",
    "    np.random.seed(100)\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(labels)))\n",
    "    x_shuffled = np.array(all_text_test)[shuffle_indices.astype(float)]\n",
    "    y_shuffled = np.array(labels)[shuffle_indices.astype(int)]\n",
    "\n",
    "    # Split train/test set\n",
    "    # dev_sample_index = -1 * int(dev_sample_percentage * len(labels))\n",
    "    train, test, train_labels, test_labels = sklearn.model_selection.train_test_split(x_shuffled, y_shuffled, test_size=.2,\n",
    "                                                                                      random_state=42)\n",
    "    train, val, train_labels, val_labels = sklearn.model_selection.train_test_split(train, train_labels, test_size=.1,\n",
    "                                                                                    random_state=42)\n",
    "    # x_train, x_val = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "    # y_train, y_val = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "    del datas, labels, x_shuffled, y_shuffled, all_text_test\n",
    "    return  train, val, train_labels, val_labels,test, test_labels\n",
    "\n",
    "\n",
    "datas = []\n",
    "labels = []\n",
    "for file in files:\n",
    "    with open(file + \"cut.txt\", 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            datas.append(line.strip(\"\\n\"))\n",
    "            labels.append(classes[file])\n",
    "print(len(datas))\n",
    "print(len(labels))\n",
    "plt.figure()\n",
    "plt.hist(train_df.cutwordnum,bins=100)\n",
    "plt.xlabel(\"词组长度\",fontproperties = fonts,size = 12)\n",
    "plt.ylabel(\"频数\",fontproperties = fonts,size = 12)\n",
    "plt.title(\"训练数据集\",fontproperties = fonts)\n",
    "plt.show()\n",
    "# train, val, train_labels, val_labels, test, test_labels= shuffleData(datas,labels,tokenflag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train,bins=100,color='red',histtype='stepfilled',alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
