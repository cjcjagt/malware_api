import numpy as np
import pandas as pd
from keras import Sequential
from keras.layers import Masking, LSTM, Dense

batch_size=128
num_step = 100
class_num = 8
sequence_length = 10000
dev_sample_percentage = 0.2

def lstm(dimension):
    model = Sequential()
    model.add(Masking(mask_value=0, input_shape=(dimension,1)))
    model.add(LSTM(50, dropout=0.2))
    # model.add(LSTM(100, return_sequences=False))
    model.add(Dense(8, activation='softmax'))
    model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    return model

def data_iter(data, batch_size, ecoph_num, shuffle=True):
    data = np.array(data)
    data_size = len(data)
    batch_count = int((data_size - 1) / batch_size) + 1
    print("data_size: {}".format(data_size))
    print("batch_count: {}".format(batch_count))
    for e in range(ecoph_num):
        shuffle_data = data
        if shuffle:
            shuffle_indices = np.random.permutation(np.arange(data_size))
            shuffle_data = data[shuffle_indices]

        for i in range(batch_count):
            yield shuffle_data[i * batch_size: min((i + 1) * batch_size,data_size)]


def train(x_train,y_train,x_val,y_val,em):
    model = lstm(sequence_length)
    model.fit(x_train, y_train, batch_size=batch_size, epochs=num_step,shuffle=True,
                        validation_data=(x_val,y_val))
    loss, acc = model.evaluate(x_val,y_val, batch_size=batch_size)
    print("\nTest score: %.3f, accuracy: %.3f" % (loss, acc))

def main():
    with open("Predata.txt",'r') as f:
        seq = []
        leng = 0
        results = []
        for line in f:
            seq = line.split(" ")
            index = max(seq)
            if leng < int(max(seq)):
                leng = int(max(seq))
            seq += ['0' for _ in range(10000 - len(seq))]
            results.append(seq)
    labels = pd.read_csv("label.csv")
    labels = np.array(labels)
    labels=labels.tolist()

    np.random.seed(100)
    shuffle_indices = np.random.permutation(range(len(results)))
    x_shuffled = np.array(results)[shuffle_indices.astype(int)]
    y_shuffled = np.array(labels)[shuffle_indices.astype(int)]

    # Split train/test set
    dev_sample_index = -1 * int(dev_sample_percentage * len(labels))
    x_train, x_val = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]
    y_train, y_val = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]

    del results, labels, x_shuffled, y_shuffled
    print("Vocabulary Size: {:d}".format(leng))
    print("Train/Dev split: {:d}/{:d}".format(len(y_train), len(y_val)))
    # x_train = vectorize(x_train,leng+1)
    # x_val = vectorize(x_val,leng+1)

    x_train = x_train.reshape(len(x_train),sequence_length,1)
    x_val = x_val.reshape( len(x_val), sequence_length,1)
    train(x_train,y_train,x_val,y_val,leng+1)

if __name__ == '__main__':
    main()

import os
import gensim
import numpy as np
from keras_preprocessing.sequence import pad_sequences
from sklearn import metrics
from sklearn.ensemble import RandomForestClassifier

files = {"Spyware", "Downloader", "Trojan", "Worms", "Adware", "Dropper", "Virus", "Backdoor"}
classes = {"Spyware": 0, "Downloader": 1, "Trojan": 2, "Worms": 3, "Adware": 4, "Dropper": 5, "Virus": 6, "Backdoor": 7}
dev_sample_percentage = 0.3
batch_size = 128
num_step = 2
class_num = 8
sequence_length = 7000
embedding = 100


class MySentences(object):
    def __init__(self, dirname):
        self.dirname = dirname

    def __iter__(self):
        for fname in os.listdir(self.dirname):
            print(str(fname) + " is doing")
            for line in open(os.path.join(self.dirname, fname)):
                yield line.split()


def shuffleData(datas, labels, tokenflag=False):
    all_text_seq = []
    array = []
    if (tokenflag):
        sentences = MySentences('data/')  # a memory-friendly iterator
        model = gensim.models.Word2Vec(sentences, min_count=0)
        model.save('myWord2VecModel.model')

    gensim_model = gensim.models.Word2Vec.load('myWord2VecModel.model')
    print(len(gensim_model.wv.vocab))
    # for word in gensim_model.wv.vocab:
    # 	print(word,gensim_model[word])
    # print(datas)
    for line in datas:
        # array = [gensim_model[word] for word in line.split(" ") if word in gensim_model]
        all_text_seq.append([gensim_model[word] for word in line.split(" ") if word in gensim_model].mean(axis=0))
    print(len(all_text_seq[0][0]))
    # print(type(line))
    # print(line)
    # for word in line.split(" "):
    # print(word)
    all_text_test = pad_sequences(all_text_seq, maxlen=sequence_length, padding='post', value=0)

    label_one_hot = np.zeros((len(labels), class_num), dtype=np.int)
    for i in range(len(labels)):
        label_one_hot[i][labels[i]] = 1
    np.random.seed(100)
    del all_text_seq
    shuffle_indices = np.random.permutation(np.arange(len(labels)))
    x_shuffled = np.array(all_text_test)[shuffle_indices.astype(int)]
    y_shuffled = np.array(labels)[shuffle_indices.astype(int)]

    # Split train/test set
    dev_sample_index = -1 * int(dev_sample_percentage * len(labels))
    x_train, x_val = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]
    y_train, y_val = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]
    del datas, labels, x_shuffled, y_shuffled, all_text_test
    return x_train, x_val, y_train, y_val


def main():
    datas = []
    labels = []
    for file in files:
        with open(file + "cut.txt", 'r') as f:
            for line in f.readlines():
                datas.append(line.strip("\n"))
                labels.append(classes[file])
    print(len(datas))
    print(len(labels))


    x_train, x_val, y_train, y_val = shuffleData(datas, labels, tokenflag=False)
    print(x_train.shape)
    x_train = x_train.reshape(len(x_train), sequence_length, 100)
    x_val = x_val.reshape(len(x_val), sequence_length, 100)
    print(x_train.shape)
    forest = RandomForestClassifier(oob_score=True, n_estimators=200, random_state=42)
    forest = forest.fit(x_train, y_train)
    print("\n====================评估以word2vec为文本表示训练的模型==================\n")
    print("1、混淆矩阵为：\n")
    print(metrics.confusion_matrix(y_train, forest.predict(x_train)))

    print("\n2、准确率、召回率和F1值为：\n")
    print(metrics.classification_report(y_train, forest.predict(x_train)))

    print("\n3、包外估计为：\n")
    print(forest.oob_score_)

    print("\n4、AUC Score为：\n")
    y_predprob = forest.predict_proba(x_train)[:, 1]
    print(metrics.roc_auc_score(y_train, y_predprob))


if __name__ == '__main__':
    main()


