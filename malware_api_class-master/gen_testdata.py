import gensim
import numpy as np
from keras.preprocessing.sequence import pad_sequences


files = {"Spyware", "Downloader", "Trojan", "Worms", "Adware", "Dropper", "Virus", "Backdoor"}
classes = {"Spyware": 0, "Downloader": 1, "Trojan": 2, "Worms": 3, "Adware": 4, "Dropper": 5, "Virus": 6, "Backdoor": 7}

batch_size = 128
num_step = 150
class_num = 8
sequence_length = 5000
embedding = 50
dev_sample_percentage = 0.2



def shuffleData(datas, labels, tokenflag=False):
    all_text_seq = []
    seq = []
    num = 1
    gensim_model = gensim.models.Word2Vec.load('D:/document/thesis/pro/graduate/malware_data/myWord2VecModel.model')

    vocab_list = list(gensim_model.wv.vocab.keys())
    word_index = {word: index for index, word in enumerate(vocab_list)}
    for line in datas:
        lineWords = line.split(" ")
        for index in range(len(lineWords)-1):
            if num < sequence_length:
                if lineWords[index] in word_index and lineWords[index]!=lineWords[index+1] :
                    seq.append(word_index[lineWords[index]]+1)
                    num += 1
                else:
                    pass
        all_text_seq.append(seq)
        seq = []
        num =1

    print(type(all_text_seq))
    all_text_test = pad_sequences(all_text_seq, maxlen=sequence_length, padding='post')
    all_text_tests=np.array(all_text_test)
    print(all_text_tests.shape)
    np.savetxt("D:/document/thesis/pro/graduate/malware_data/test_data.txt", all_text_tests)
    # for i in all_text_seq:

    # all_text_test = pad_sequences(all_text_seq, maxlen=sequence_length, padding='post')
    # np.savetxt("D:/document/thesis/pro/graduate/malware_data/test_data.txt",all_text_test)

    # np.random.seed(1226)
    # del all_text_seq
    # shuffle_indices = np.random.permutation(np.arange(len(labels)))
    # x_shuffled = np.array(all_text_test)[shuffle_indices.astype(int)]
    # y_shuffled = np.array(labels)[shuffle_indices.astype(int)]
    #
    # dev_sample_index = -1 * int(dev_sample_percentage * len(labels))
    # train, val = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]
    # train_labels, val_labels = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]
    # del datas, labels, x_shuffled, y_shuffled, all_text_test
    # print(type(val))
    # np.savetxt("D:/document/thesis/pro/graduate/malware_data/test_data.txt",val)
    # np.savetxt("D:/document/thesis/pro/graduate/malware_data/test_label.txt",val_labels)


def main():
    datas = []
    labels = []
    for file in files:
        with open("D:/document/thesis/pro/graduate/malware_data/"+file + "cut.txt", 'r') as f:
            for line in f.readlines():
                datas.append(line.strip("\n"))
                labels.append(classes[file])

    # print(len(datas[100]))
    shuffleData(datas,labels,tokenflag=False)



if __name__ == '__main__':
    main()

