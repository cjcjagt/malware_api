import os
import gensim
import numpy as np
from keras import Sequential
from keras.layers import Masking, LSTM, Dense, Bidirectional
from keras.preprocessing.sequence import pad_sequences
from keras.callbacks import ReduceLROnPlateau

files = {"Spyware", "Downloader", "Trojan", "Worms", "Adware", "Dropper", "Virus", "Backdoor"}
classes = {"Spyware": 0, "Downloader": 1, "Trojan": 2, "Worms": 3, "Adware": 4, "Dropper": 5, "Virus": 6, "Backdoor": 7}
dev_sample_percentage = 0.3
batch_size = 128
num_step = 100
class_num = 8
sequence_length = 7000
embedding = 100


class MySentences(object):
    def __init__(self, dirname):
        self.dirname = dirname

    def __iter__(self):
        for fname in os.listdir(self.dirname):
            print(str(fname) + " is doing")
            for line in open(os.path.join(self.dirname, fname)):
                yield line.split()


def shuffleData(datas, labels, tokenflag=False):
    all_text_seq = []
    array = []
    if (tokenflag):
        sentences = MySentences('data/')  # a memory-friendly iterator
        model = gensim.models.Word2Vec(sentences, min_count=0)
        model.save('myWord2VecModel.model')

    gensim_model = gensim.models.Word2Vec.load('myWord2VecModel.model')
    print(len(gensim_model.wv.vocab))
    for line in datas:
        # array = [gensim_model[word] for word in line.split(" ") if word in gensim_model]
        all_text_seq.append([gensim_model[word] for word in line.split(" ") if word in gensim_model])
    print(len(all_text_seq))
    all_text_test = pad_sequences(all_text_seq, maxlen=sequence_length, padding='post', value=0)

    # label_one_hot = np.zeros((len(labels), class_num), dtype=np.int)
    # for i in range(len(labels)):
    #     label_one_hot[i][labels[i]] = 1
    np.random.seed(100)
    del all_text_seq
    shuffle_indices = np.random.permutation(np.arange(len(labels)))
    x_shuffled = np.array(all_text_test)[shuffle_indices.astype(int)]
    y_shuffled = np.array(labels)[shuffle_indices.astype(int)]

    # Split train/test set
    dev_sample_index = -1 * int(dev_sample_percentage * len(labels))
    x_train, x_val = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]
    y_train, y_val = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]
    del datas, labels, x_shuffled, y_shuffled, all_text_test
    return x_train, x_val, y_train, y_val


def lstm(embedding):
    model = Sequential()
    model.add(Masking(mask_value=0, input_shape=(sequence_length, embedding)))
    model.add(Bidirectional(LSTM(50, dropout=0.3, return_sequences=True)))

    # model.add(LSTM(100, return_sequences=False))
    model.add(Dense(8, activation='softmax'))
    model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
    return model


def main():
    datas = []
    labels = []
    for file in files:
        with open(file + "cut.txt", 'r') as f:
            for line in f.readlines():
                datas.append(line.strip("\n"))
                labels.append(classes[file])
    print(len(datas))
    print(len(labels))

    # print(len(datas[100]))
    # shuffleData(datas,labels,tokenflag=False)
    x_train, x_val, y_train, y_val = shuffleData(datas, labels, tokenflag=False)

    print(x_train.shape)
    model = lstm(embedding)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')
    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_step, shuffle=True,
                        validation_data=(x_val, y_val), callbacks=[reduce_lr])

    loss, acc = model.evaluate(x_val, y_val, batch_size=batch_size)
    model.save("my2VecModel.h5")
    print("\nTest score: %.3f, accuracy: %.3f" % (loss, acc))
    with open("./log/test.log", "a+") as f:
        f.write("\nval_loss-----------------------\n")
        f.write(str(history.history['val_loss']))
        f.write("\nval_acc-----------------------\n")
        f.write(str(history.history['val_accuracy']))
        f.write("\nloss--------------------------\n")
        f.write(str(history.history['loss']))
        f.write("\nacc---------------------------\n")
        f.write(str(history.history['accuracy']))

        f.write("\nTest loss:" + str(round(loss, 3)) + ", accuracy:" + str(round(acc, 3)))


if __name__ == '__main__':
    main()

