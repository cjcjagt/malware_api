# -*- coding: utf-8 -*-
"""lemna.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v98GmeeGQyKPjCgmAlToyy-NBZSL3EmP
"""

# !pip install lime

from google.colab import drive, files
import numpy as np
import pickle
from keras.preprocessing.sequence import pad_sequences
# from lime.lime_text import LimeTextExplainer
# from lime.lime_tabular import LimeTabularExplainer
import matplotlib.pyplot as plt
from keras.utils import to_categorical
import tensorflow as tf
from sklearn.pipeline import make_pipeline
from sklearn.metrics import precision_score
from sklearn.metrics import classification_report
from sklearn.metrics import multilabel_confusion_matrix

config = tf.compat.v1.ConfigProto(allow_soft_placement=True)
sess = tf.compat.v1.Session(config=config)
drive.mount('/content/drive')

with open("security_train.csv.pkl", "rb") as f:
    labels = pickle.load(f)
    files = pickle.load(f)

labels = np.asarray(labels)
y_true = list(map(int,labels))

with open("wordsdic.pkl", 'rb') as f:
    tokenizer = pickle.load(f)

maxlen = 6000

x_train_word_ids = tokenizer.texts_to_sequences(files)

x_train = pad_sequences(x_train_word_ids, maxlen=maxlen)

model = pickle.load(open('/content/drive/My Drive/Colab Notebooks/newmodel/model_dila_testcnn_4.sav', 'rb'))

ytrain = list(model.predict(x_train))
y_pred = np.argmax(ytrain,axis=1)
def kappa(matrix):
    n = np.sum(matrix)
    sum_po = 0
    sum_pe = 0
    for i in range(len(matrix[0])):
        sum_po += matrix[i][i]
        row = np.sum(matrix[i, :])
        col = np.sum(matrix[:, i])
        sum_pe += row * col
    po = sum_po / n
    pe = sum_pe / (n * n)
    # print(po, pe)
    return (po - pe) / (1 - pe)
with open("metric.txt", 'w+') as f:
    print("labels*************************************")
    print(y_true)
    f.write("labels*************************************")
    f.write('\r\n')
    f.write(str(y_true))
    f.write('\r\n')
   

    print("y_pred*************************************")
    print(y_pred)
    f.write("y_pred*************************************")
    f.write('\r\n')
    f.write(str(y_pred))
    f.write('\r\n')
    matrix = multilabel_confusion_matrix(y_true, y_pred)
    print("matrix--------------------------")
    print(matrix)
    f.write("matrix--------------------------")
    f.write('\r\n')
    f.write(str(matrix))
    f.write('\r\n')
    metric = kappa(matrix)
    print("kappa metric--------------------------")
    print(metric)
    f.write("kappa metric--------------------------")
    f.write('\r\n')
    f.write(str(metric))
    f.write('\r\n')
    print("classification_report--------------------------")
    target_names = ['class 0','class 1','class 2','class 3','class 4','class 5','class 6','class 7']
    report = classification_report(y_true, y_pred, target_names=target_names)
    print(report)
    f.write("report--------------------------")
    f.write('\r\n')
    f.write(str(report))
    f.write('\r\n')
    print("precision--------------------------")
    precision=precision_score(y_true, y_pred, average='macro',pos_label="1")  
    print(precision)
    f.write("precision--------------------------")
    f.write('\r\n')
    f.write(str(precision))
    f.write('\r\n')

